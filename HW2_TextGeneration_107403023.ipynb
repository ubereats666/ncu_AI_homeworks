{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-107403023.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "\n",
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "**把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erBBqHI9bHwD"
      },
      "source": [
        "# 開始執行前請先在心中默念著作權相關法律，並發誓只將資料集用於教學用途\n",
        "# 請下載失去著作權保護期的書籍 (50年)\n",
        "# 執行即代表已完成閱讀著作權辦法，並同意遵循著作權相關條例\n",
        "\n",
        "import requests\n",
        "from lxml import etree\n",
        "import re \n",
        "import urllib\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "if(os.path.isdir(\"./books\") == False):\n",
        "  os.mkdir(\"./books\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu-ybl-DbHk-"
      },
      "source": [
        "def get_book_information(url):\n",
        "  url_chinese = urllib.parse.unquote(url)\n",
        "  url_re = re.compile(r'com/(.*)\\.php')\n",
        "  url_re2 = re.compile(r'.*\\.php')\n",
        "  url_re3 = re.compile(r'\\.(html|xhtml)')\n",
        "  save_path = \"./books/\"+url_re.search(url_chinese).group(1).strip()+\".txt\"\n",
        "  url_book_domain = url_re2.match(url).group(0)\n",
        "  html_format = url_re3.search(url).group(0)\n",
        "  print(\"儲存位置: \"+save_path)\n",
        "  return save_path,url_book_domain,html_format\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nada28TUbHVF"
      },
      "source": [
        "def get_pages_of_book(url):\n",
        "  response = requests.get(url+\"#book_toc\")\n",
        "  html = etree.HTML(response.content)\n",
        "  content_number = len(html.xpath('.//div[@data-role=\"content\"]//ul/li'))\n",
        "  return content_number\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6acc3ae-9dbb-4283-abf6-9d0e60c9c405"
      },
      "source": [
        "def download_one_book(url):\n",
        "  save_path,url_book_domain,html_format = get_book_information(url)\n",
        "  content_number = get_pages_of_book(url)\n",
        "  page_start = 2 if(html_format == \".html\") else 1\n",
        "  page_end = page_start+content_number\n",
        "  file = open(save_path,\"w\",encoding=\"utf8\")\n",
        "  for page in tqdm(range(page_start,page_end)):\n",
        "      if(html_format == \".html\"):\n",
        "          url_ = url_book_domain+\"/\"+(str(page) if page>9 else \"0\"+str(page))+html_format\n",
        "      else:\n",
        "          url_ = url_book_domain+\"/\"+str(page)+html_format\n",
        "      response = requests.get(url_)\n",
        "      html = etree.HTML(response.content.decode(\"utf-8\",\"replace\"))\n",
        "      if(html_format == \".html\"):\n",
        "          content = html.xpath('.//div[@data-role=\"content\"]/p/text()')\n",
        "      else:\n",
        "          content = html.xpath('.//div[@data-role=\"content\"]/div/text()')\n",
        "      assey = [a.strip().replace(\"\\u3000\",\" \") for a in content]\n",
        "      file.write(\"\\n\".join(assey)+\"\\n\")\n",
        "  file.flush()\n",
        "  file.close()\n",
        "\n",
        "url = \"https://www.bookscool.com/%E5%8D%A1%E7%B9%86-%E7%95%B0%E9%84%89%E4%BA%BA.php/0.xhtml\"\n",
        "download_one_book(url)\n",
        "\n",
        "\n",
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非商業用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "\n",
        "#!wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "儲存位置: ./books/卡繆-異鄉人.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:07<00:00,  1.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "30d42bc8-d3d4-4a09-c380-976b4abd0997"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"/content/books/卡繆-異鄉人.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "共有 55660 字詞\n",
            "包含了 2127 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一五年三月六日版》\n",
            "《好讀書櫃》典藏版\n",
            "第一部\n",
            "１\n",
            "今天，媽媽死了。也許是昨天，我不知道。我收到養老院的一封電報，說：「母死。明日葬。專此通知。」這說明不了什麼。可能是昨天死的。\n",
            "養老院在馬朗戈，離阿爾及爾八十公里。我乘兩點鐘的公共汽車，下午到，還趕得上守靈，明天晚上就能回來。我向老闆請了兩天假，有這樣的理由，他不能拒絕。不過，他似乎不大高興。我甚至跟他說：「這可不是我的錯兒。」他沒有理我。我想我不該跟他說這句話。反正，我沒有什麼可請求原諒的，倒是他應該向我表示哀悼。不過，後天他看見我戴孝的時候，一定會安慰我的。現在有點像是媽媽還沒有死似的，不過一下葬，那可就是一樁已經了結的事了，一切又該公事公辦了。\n",
            "我乘的是兩點鐘的汽車。天氣很熱。跟平時一樣，我還是在賽萊斯特的飯館裡吃的飯。他們都為我難受，賽萊斯特還說：「人只有一個母親啊。」我走的時候，他們一直送我到門口。我有點兒煩，因為我還得到艾瑪努埃爾那裡去借黑領帶和黑紗。他幾個月前剛死了叔叔。\n",
            "為了及時上路，我是跑著去的。這番急，這番跑，加上汽車顛簸，汽油味兒，還有道路和天空亮得晃眼，把我弄得昏昏沉沉的。我幾乎睡了一路。我醒來的時候，\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "ea71b09e-d3ab-4e4b-e0f8-bfc2f220d372"
      },
      "source": [
        "stop_word = 1\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "去除次數小於1的文字剩餘 : 1650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "8f58ed03-dd5d-4551-8cd9-9c7bd25d9a77"
      },
      "source": [
        "print(f\"原本的書共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的書共有 55660 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘55183個字\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "46ea6fb7-0563-4eb3-f85a-3be89ec0be29"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '○', '一', '五', '年', '三', '月', '六', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典', '藏', '版', '\\n', '第', '一', '部', '\\n', '１', '\\n', '今', '天', '，', '媽', '媽', '死', '了', '。', '也', '許']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{0, 1, 1297, 1046, 1176, 1561, 1439, 1444, 1576, 297, 298, 299, 1202, 1606, 1611, 1357, 462, 1618, 1366, 1367, 1368, 1113, 1245, 1643, 1644, 1648, 1649, 1140, 1141, 1524, 1017}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "ce0d9636-ed57-466e-e258-8537a84c48c2"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1618 1366 1357  297 1644 1046 1444 1367 1140 1113 1176  298 1368 1618\n",
            " 1366 1576 1202 1017  462 1368    0], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '○', '一', '五', '年', '三', '月', '六', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[ 299  298 1618 1439 1644 1245 1618    1 1618 1141 1606 1649 1561 1561\n",
            " 1524 1643 1648 1611 1297 1642  893], shape=(21,), dtype=int32)\n",
            "['藏', '版', '\\n', '第', '一', '部', '\\n', '１', '\\n', '今', '天', '，', '媽', '媽', '死', '了', '。', '也', '許', '是', '昨']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "a36c07df-0691-44e5-a61b-d86ab05408b6"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "6fa68026-473c-45e8-e194-1cdf48339f1f"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : ['\\n', '《', '二', '○', '一', '五', '年', '三', '月', '六', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》']\n",
            "Target: ['《', '二', '○', '一', '五', '年', '三', '月', '六', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典']\n",
            "--------------------------------------------------\n",
            "Input : [1618 1366 1357  297 1644 1046 1444 1367 1140 1113 1176  298 1368 1618\n",
            " 1366 1576 1202 1017  462 1368]\n",
            "Target: [1366 1357  297 1644 1046 1444 1367 1140 1113 1176  298 1368 1618 1366\n",
            " 1576 1202 1017  462 1368    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "b4356187-4c91-44ec-db32-3b8584b35c39"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 20), (64, 20)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "d2d1ade7-3364-4826-cf28-0a9cda8aa114"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 512)         844800    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 4096)        75513856  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 2048)        50339840  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 1650)        3380850   \n",
            "=================================================================\n",
            "Total params: 130,079,346\n",
            "Trainable params: 130,079,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "00ceeff3-2b86-4065-e187-146d7f610db7"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1650)\n",
            "Model target shape : (64, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "0e03551c-edd3-479d-b0a3-096a2a4474c1"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "我。如果另一個上了，或是他掏出了刀子，我\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "拾ＰＰＰＰ薄咂咂咂咂咂話話勾勾勾勾民民美\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "9703fb54-cdef-4ad8-c4ab-7441b8e19403"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        "    \n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "41/41 [==============================] - 16s 343ms/step - loss: 6.8743\n",
            "Epoch 2/20\n",
            "41/41 [==============================] - 15s 354ms/step - loss: 5.9218\n",
            "Epoch 3/20\n",
            "41/41 [==============================] - 15s 367ms/step - loss: 5.8434\n",
            "Epoch 4/20\n",
            "41/41 [==============================] - 15s 372ms/step - loss: 5.7997\n",
            "Epoch 5/20\n",
            "41/41 [==============================] - 15s 363ms/step - loss: 5.6133\n",
            "Epoch 6/20\n",
            "41/41 [==============================] - 15s 356ms/step - loss: 5.3748\n",
            "Epoch 7/20\n",
            "41/41 [==============================] - 15s 355ms/step - loss: 5.1604\n",
            "Epoch 8/20\n",
            "41/41 [==============================] - 15s 360ms/step - loss: 4.9957\n",
            "Epoch 9/20\n",
            "41/41 [==============================] - 15s 365ms/step - loss: 4.7949\n",
            "Epoch 10/20\n",
            "41/41 [==============================] - 15s 364ms/step - loss: 4.6085\n",
            "Epoch 11/20\n",
            "41/41 [==============================] - 15s 362ms/step - loss: 4.4221\n",
            "Epoch 12/20\n",
            "41/41 [==============================] - 15s 360ms/step - loss: 4.2453\n",
            "Epoch 13/20\n",
            "41/41 [==============================] - 15s 361ms/step - loss: 4.0397\n",
            "Epoch 14/20\n",
            "41/41 [==============================] - 15s 361ms/step - loss: 3.7997\n",
            "Epoch 15/20\n",
            "41/41 [==============================] - 15s 363ms/step - loss: 3.5915\n",
            "Epoch 16/20\n",
            "41/41 [==============================] - 15s 364ms/step - loss: 3.3484\n",
            "Epoch 17/20\n",
            "41/41 [==============================] - 15s 365ms/step - loss: 3.0843\n",
            "Epoch 18/20\n",
            "41/41 [==============================] - 15s 363ms/step - loss: 2.8046\n",
            "Epoch 19/20\n",
            "41/41 [==============================] - 15s 362ms/step - loss: 2.5212\n",
            "Epoch 20/20\n",
            "41/41 [==============================] - 15s 362ms/step - loss: 2.1878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "19d2ac07-42a9-47e4-bbd9-d5bad51d75e6"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfrG8e+THgidgPSOCEgRpFcRxIKAulZsiIiyCGJZ3d+u7qq7q2tBBVTEirKIoigKgihIlRJ6J1QBIaFDKAHC+/tjBo1IMJDMnGTm/lzXXJmcMufJycydk/e85z3mnENEREJPhNcFiIhIYCjgRURClAJeRCREKeBFREKUAl5EJEQp4EVEQpQCXgQws/fN7NlsLrvJzC7P6euIBJoCXkQkRCngRURClAJe8g1/08ijZrbUzA6Z2TtmVtrMvjGzg2b2nZkVy7T8tWa2wsz2mdkPZnZRpnkNzWyhf73RQNxp27rGzBb7151tZvXOs+Z7zWydme0xs3FmVtY/3cxskJmlmtkBM1tmZnX9864ys5X+2raZ2SPntcMk7CngJb+5HugI1AS6AN8AfwUS8b2fHwQws5rAKGCAf94E4CszizGzGOAL4EOgOPCp/3Xxr9sQeBe4DygBDAPGmVnsuRRqZpcB/wFuBMoAm4GP/bM7AW38P0cR/zK7/fPeAe5zzhUC6gJTzmW7Iqco4CW/GeycS3HObQNmAHOdc4ucc0eBsUBD/3I3AeOdc5Odc8eBF4F4oAXQDIgGXnHOHXfOjQHmZ9pGb2CYc26ucy7DOfcBkO5f71zcBrzrnFvonEsHngCam1ll4DhQCKgFmHNulXNuu3+940BtMyvsnNvrnFt4jtsVARTwkv+kZHp+5AzfJ/ifl8V3xAyAc+4ksAUo55+3zf12pL3NmZ5XAh72N8/sM7N9QAX/eufi9BrS8B2ll3POTQGGAEOBVDN7y8wK+xe9HrgK2Gxm08ys+TluVwRQwEvo+hlfUAO+Nm98Ib0N2A6U8087pWKm51uAfznnimZ6FHDOjcphDQXxNflsA3DOveacawTUxtdU86h/+nznXFegFL6mpE/OcbsigAJeQtcnwNVm1sHMooGH8TWzzAZ+BE4AD5pZtJldBzTJtO5woI+ZNfWfDC1oZlebWaFzrGEUcLeZNfC33/8bX5PSJjO71P/60cAh4Chw0n+O4DYzK+JvWjoAnMzBfpAwpoCXkOScWwP0AAYDu/CdkO3inDvmnDsGXAfcBezB117/eaZ1k4B78TWh7AXW+Zc91xq+A/4OfIbvv4ZqwM3+2YXx/SHZi68ZZzfwgn/e7cAmMzsA9MHXli9yzkw3/BARCU06ghcRCVEKeBGREKWAFxEJUQp4EZEQFeV1AZmVLFnSVa5c2esyRETyjQULFuxyziWeaV6eCvjKlSuTlJTkdRkiIvmGmW3Oap6aaEREQpQCXkQkRCngRURClAJeRCREKeBFREKUAl5EJEQp4EVEQlS+D/gTGSd5c9p6Fv601+tSRETylHwf8EdPnOSD2Zt44rNlHDuh+yKIiJyS7wM+ITaKZ7vVZU3KQYZNW+91OSIieUa+D3iADheV5pp6ZRg8ZR3rUtO8LkdEJE8IiYAHeKpLHeJjInni86WcPKm7VImIhEzAJxaK5W9XX8T8TXsZNf8nr8sREfFcyAQ8wA2NytOyegmem7CaHfuPel2OiIinQirgzYx/d7+YYxkn+fuXy9ENxUUknIVUwANUKlGQgR1rMnllChOX7/C6HBERz4RcwAPc06oKdcoW5slxK9h/+LjX5YiIeCIkAz4qMoLnr6/HnkPHeG7iKq/LERHxREgGPEDdckXo1aoKo+Zt4cf1u70uR0Qk6EI24AEGXF6TisUL8Nexyzh6PMPrckREgiqkAz4+JpJ/d7+YjbsO8dr3yV6XIyISVCEd8ACtapTkhkbleWv6Blb+fMDrckREgibkAx7g/666iKIFonn886VkaBgDEQkTYRHwxQrG8FSXOizdup/3Zm30uhwRkaAIi4AHuKZeGS6rVYqXvl3Llj2HvS5HRCTgwibgzYxnutUlwuCvY5dpGAMRCXkBDXgzK2pmY8xstZmtMrPmgdzeHylXNJ7HOtdiRvIuvli8zctSREQCLtBH8K8CE51ztYD6gOeXlfZoVolLKhbl6a9Wsjst3etyREQCJmABb2ZFgDbAOwDOuWPOuX2B2l52RUYYz11fj7T0Ezzz9UqvyxERCZhAHsFXAXYC75nZIjN728wKnr6QmfU2syQzS9q5c2cAy/lVzdKFuL9ddb5Y/DNT16QGZZsiIsEWyICPAi4B3nDONQQOAY+fvpBz7i3nXGPnXOPExMQAlvNbfdtXo1piQf42djmH0k8EbbsiIsESyIDfCmx1zs31fz8GX+DnCbFRkTx/fT227TvCS9+u9bocEZFcF7CAd87tALaY2YX+SR2APNXo3bhycXo0q8h7szfy4ZzNLN+2nyPHNCiZiISGqAC/fj9gpJnFABuAuwO8vXP2l861mL1uN3//YjkAZlChWAFqlEqgeukEapYqRI3SCVQvlUCBmEDvLhGR3BPQxHLOLQYaB3IbOVUoLppJD7Vh8+5DJKeksTYljeTUgySnpDE9eSfHM369IKp8sXhqli5EjVIJ1PB/rV4qgYKxCn4RyXuUTEB0ZATVSxWieqlCXHnxr9NPZJxk857DJKf4An9tahrJKQeZmbyLYxknf1muXNF46lcoQpPKxWlatQQXli5ERIR58JOIiPxKAX8WUZERVEtMoFpiAp3r/jr9RMZJftpzmGR/4K9JSWPh5r1MWOa7yXfRAtFcWrk4TasUp2mVEtQuW5hIBb6IBJkC/jxERUZQNTGBqokJXFHngl+mb917mLkb9jB3427mbdzD5JUpABSKjaJR5WI0rVKCplWLc3G5IkRHhs0wQCLiEQV8LipfrADlGxXg+kblAdix/+gvYT934x5+WLMagPjoSBpVKkbTKsVpUqU49SsUJS460svSRSQEWV4aVbFx48YuKSnJ6zICZldaOvM27mHexj3M2bCb1TsOAhATFcE1F5fh4SsupFzReI+rFJH8xMwWOOfO2JlFAe+hfYePMX/TXqav3cnopC0A3NOqCve3q0bhuGiPqxOR/EABnw9s3XuYl75dy9hF2yheMIb+HWpwa9OKaqsXkbM6W8ArPfKI8sUKMOimBnz151bULJ3AU+NWcMWg6UxasUM3JxGR86KAz2MuLl+EUfc24+07GmMG9324gJuGzWHxFs9HWhaRfEYBnweZGZfXLs2kAW14tltdNuxKo9vQWTw4apHuJysi2aY2+HwgLf0Ew6atZ/iMDZw8CXe1rEzfdtUpUkAnYkXCndrg87mE2Cge7nQhUx9px7UNyjJ8xgbavjiVd2du5NiJk3/8AiISlhTw+UiZIvG8+Kf6fN2vFXXKFubpr1fScdA0JizbrhOxIvI7Cvh8qE7ZInx0T1Peu/tSYqMieGDkQnq8M5ete9U+LyK/UsDnU2ZG+wtLMeHB1jzTrS6Lf9pH51dmMHr+TzqaFxFAAZ/vRUVGcHuzSkwc0Ia65Qrzl8+W0fP9+aQcOOp1aSLiMQV8iKhQvAD/69WMp7rU5scNu+k0aDpfLt6mo3mRMKaADyEREcbdLasw4cHWVE0sSP+PF3P/RwvZlZbudWki4gEFfAiqmpjAmD4tePzKWkxZncoVg6Yzcfl2r8sSkSBTwIeoyAijT9tqfNWvFWWKxtHno4X0/3gR+w4f87o0EQkSBXyIu/CCQox9oCUPXV6T8Uu302nQdKauTvW6LBEJAgV8GIiOjKD/5TX4om9LihWI4e735/PYmCUcPHrc69JEJIAU8GGkbrkijOvXkvvbVWPMgq10fmUGs9bt8rosEQkQBXyYiY2K5C+dazHm/hbERkVw29tzefLL5Rw+dsLr0kQklyngw9QlFYsx/sHW9GxZhRE/buayF6cxZsFWTp5Uv3mRUKGAD2PxMZE82aU2Y/o0p3ThWB75dAnXDJ7JbDXbiIQEBbzQuHJxxj7QkldvbsD+I8e59e253PP+fNalHvS6NBHJAQW8AL6rYLs2KMf3D7fl8StrMW/jHq54ZQZ/+2KZroQVyacU8PIbcdGR9GlbjR8ebUePphUZNW8L7V74gaFT13H0eIbX5YnIOVDAyxmVSIjln13r8u1DbWherQQvTFrDZS/+wOcLdSJWJL9QwMtZVUtMYPgdjRl1bzNKJMQy8JMlXDt0Jj+u3+11aSLyBxTwki3Nq5Xgy74tGXRTffakHeOW4XPo9UES61LTvC5NRLKggJdsi4gwujcsz5RH2vHoFRcyZ8NurnhlOk9+uZzdOhErkudYXrohROPGjV1SUpLXZUg27UpL55Xv1jJq3hbioiLo2aoKvVpXpUh8tNeliYQNM1vgnGt8xnkKeMmpdalpDJq8lvHLtlM4Lor72lbjrhaVKRgb5XVpIiFPAS9BseLn/bz87Vq+X51KyYQY7m9XnduaViQuOtLr0kRClgJegmrB5r289O0aZq/fTZkicfS7rAZ/alye6Eid8hHJbQp48cTsdbt44ds1LPppHxWLF2DA5TXo2qAckRHmdWkiIcOzgDezTcBBIAM4kVURpyjgQ49zjqlrUnlx0lpWbj9A9VIJDOxYk851LiBCQS+SY2cL+GCcBWvvnNPwhGHKzLisVmna1SzFN8t38PLkNTwwciF1yhbmkU4X0u7CRMwU9CKBoEZRCYqICOPqemX49qG2vPSn+hw4epy735/PDW/+qKtiRQIk0E00G4G9gAOGOefeOsMyvYHeABUrVmy0efPmgNUjecexEyf5JGkLg6ckk3IgnZbVS/Bwpwu5pGIxr0sTyVe8bIMv55zbZmalgMlAP+fc9KyWVxt8+Dl6PIOP5mzmjR/Ws/vQMTrUKsVDHWtSt1wRr0sTyRfOFvABbaJxzm3zf00FxgJNArk9yX/ioiPp1boq0x9rz6NXXMj8TXu4ZvBMHhi5gOQU3XBEJCcCFvBmVtDMCp16DnQClgdqe5K/FYyNom/76sz4y2U82KEG09bspNMr03lo9GI27TrkdXki+VLAmmjMrCq+o3bw9db5n3PuX2dbR000csqeQ8cYNn09H8zexPEMx58aladfhxqUKxrvdWkieYoudJJ8K/XgUV6fup7/zf0JgFuaVKBv++qUKhzncWUieYMCXvK9n/cdYfCUdXyatIXICOPOFpXp07YaxQvGeF2aiKcU8BIyNu8+xKvfJ/PFom3ER0dqiGIJewp4CTnrUg8y6Ltkxi/9dYjini2rEB+jkSslvCjgJWRlHqL4gsJxDOxYk+sbldeAZhI2POsHLxJodcoW4Z27LmV072aULhLHY58t5apXZzB1dSp56eBFxAsKeAkJTauW4IsHWvD6bZeQfiKDu9+fzy3D57B06z6vSxPxjAJeQoaZcdXFvgHN/nltHZJT0rh2yCz6jVrET7sPe12eSNCpDV5C1sGjx3lr+gaGz9hAxklHj2aV6HdZDXWtlJCik6wS1lIOHGXQ5LV8krSFgjFR3N/e1+NG94qVUKCTrBLWSheO47nr6zFpQBuaVi3Ofyeuof2LP/BJ0hYyTuadAxyR3KaAl7BRo3Qh3r7zUj7u3YxShWJ5bIx63EhoU8BL2GlWtQRf9G3J0Fsv4ai/x82tw+eyeIt63EhoUcBLWDLz3UJw8kNt+UeX2qxNOUi3obN4YOQCNuxM87o8kVyhk6wiQFr6CYb7e9yknzjJTZdWYECHGhq1UvI89aIRyaadB9MZMiWZkXN/IirSuKdVFe5rW43CcRrMTPImBbzIOdq8+xAvfbuWcUt+pmiBaP7cvjo9mlVS10rJcxTwIudp+bb9PD9xNTOSd1GuaDwPdaxJ94blNJiZ5BnqBy9ynuqWK8KH9zRlZK+mFC8YwyOfLuGqV2cwZXWKulZKnqeAF8mGltVL8mXflgy5tSHpJzLo+X4SNw2bw4LNe70uTSRL2Qp4M+tvZoXN5x0zW2hmnQJdnEheEhFhXFOvLJMHtuWZbnXZsOsQ178xm94jkliXetDr8kR+J7tH8D2dcweATkAx4HbguYBVJZKHRUdGcHuzSkx7tB0Pd6zJ7PW76TRoOk98vpSUA0e9Lk/kF9kN+FNnlK4CPnTOrcg0TSQsFYyNol+HGkx/rD13tqjMmAVbafvCVF6YtJoDR497XZ5ItgN+gZl9iy/gJ5lZIeBk4MoSyT+KF4zhqS51+H5gO66ocwFDp66n7X+n8s7MjaSfyPC6PAlj2eomaWYRQANgg3Nun5kVB8o755bmZjHqJimhYPm2/Tz3zWpmrttF+WLxPHrFhXSpV5YIda2UAMiNbpLNgTX+cO8B/A3Yn1sFioSSuuWK8FGvpozo2YTCcdH0/3gxXYbMZEbyTq9LkzCT3YB/AzhsZvWBh4H1wIiAVSUSAtrUTOTrfq145aYG7D9ynNvfmcft78xl+TYdG0lwZDfgTzhfW05XYIhzbihQKHBliYSGiAijW8NyfP9wW/529UUs27afawbPpP/Hi9iyR/eJlcDKbsAfNLMn8HWPHO9vk9foSyLZFBsVSa/WVZn+WHseaFeNSSt20OGlaTz91Ur2HDrmdXkSorIb8DcB6fj6w+8AygMvBKwqkRBVOC6axzrX4odH2tO9YTnen72Rtv+dyus/rFOPG8l12R5szMxKA5f6v53nnEvN7WLUi0bCTXLKQZ6fuJrvVqVSqUQB/n51bTpcVAoz9biR7MlxLxozuxGYB/wJuBGYa2Y35F6JIuHp1H1iR/RsQnRkBL1GJHHne/NZl6q7SknOZbcf/BKg46mjdjNLBL5zztXPzWJ0BC/h7HjGSUb8uJlXJq/lyPEM7mpRmQcvr6GbjchZ5UY/+IjTmmR2n8O6IpIN0ZER3NOqClMfbccNjcrzzqyNXPbiD3wyfwsnT2poYjl32Q3piWY2yczuMrO7gPHAhMCVJRK+SibE8tz19RjXtxUVixfgsc+W0v31WSz8SUMTy7k5l5Os1wMt/d/OcM6Nze1i1EQj8lvOOb5c/DP/+WYVKQfSue6ScjzeuZZuBi6/0C37RPK5Q+knGDp1HW/P2Eh0pNGvQw3ublmZ2CjdIzbcnXfAm9lB4EwLGOCcc4Vzp0QfBbzI2W3adYhnx6/iu1UpVC5RgCe71OayWqW9Lks8dN4nWZ1zhZxzhc/wKJTdcDezSDNbZGZfn0/xIvKryiUL8vadjfmgZxMiIoye7ydx13vz2LBT3Srl94LRE6Y/sCoI2xEJG21rJjKxfxv+dvVFLNi0lytemc6Lk9Zw5JiuhpVfBTTgzaw8cDXwdiC3IxKOYqIi6NW6KlMeaUeX+mUZMnUdl788jckrU7wuTfKIQB/BvwI8hu7+JBIwiYViefnGBozu3YyCsZHcOyKJe96fr9EqJXABb2bXAKnOuQV/sFxvM0sys6SdO3VDBJHz1bRqCcY/2Jq/XlWLHzfs5vKXp/Ha98kaxCyMBaybpJn9B9/wwieAOKAw8LlzrkdW66gXjUju2L7/CM9+vYrxy7ZTpWRB/nltHdrUTPS6LAmA3Biq4Jw5555wzpV3zlUGbgamnC3cRST3lCkSz9DbLmFEzyYA3PHuPB4YuYDt+494XJkEk8aTEQlhbWomMnFAax7uWJPvV6XS4aVpvDV9PcczdFosHOhKVpEwsWXPYf4xbgXfr06lZukEnulal6ZVS3hdluSQJ000IpK3VChegHfuupThdzTmUHoGN701h4GjF7PzYLrXpUmAKOBFwkzH2qX5bmBb+ravxldLf+ayl35gxI+byNCQxCFHAS8ShuJjInn0ilpMHNCG+uWL8uSXK7jhzdms3nHA69IkFyngRcJYtcQEPrynCYNuqs/m3Ye55rWZvDBpNUePq+98KFDAi4Q5M6N7w/J8N7AtXRuUY+jU9XR+ZTqz1u3yujTJIQW8iABQvGAML91Yn5G9mgJw29tzefiTJew9dMzjyuR8KeBF5DdaVi/JxAFt6Nu+Gl8u3kaHl6cxdtFW8lKXaskeBbyI/E5ctO8k7NcP+u4L+9DoJdzx7jx+2q0BzPITBbyIZKnWBYX57P4WPN21Dot+2kenV6bx5jRdCZtfKOBF5KwiI4w7mldm8sA2tKmRyHPfrObaIbNYsmWf16XJH1DAi0i2lCkSz1t3NObNHo3Ycyid7q/P4p9frSAt/YTXpUkWFPAick46172AyQPbclvTSrw/exOdXp7GlNW6i1RepIAXkXNWOC6aZ7rVZUyfFiTERdHz/ST+OnYZh4/paD4vUcCLyHlrVKkYX/VrxX1tqjJq3k9c89pMlm5V23xeoYAXkRyJjYrkiasuYmSvphw5nsF1r89myJRkDV6WByjgRSRXtKhWkon929C57gW8+O1abhr2o2787TEFvIjkmiIFohl8S0MG3VSfNTsOcuWrM/h8oa6C9YoCXkRy1anByyb0b03tMoUZ+MkS/jxqEfsOa0ybYFPAi0hAVChegFG9m/HoFRcyafkOOr8yg9kaoTKoFPAiEjCREUbf9tUZ+0BLCsRGcuvbc/nX+JWkn9B488GggBeRgLu4fBHG92tNj2YVGT5jI12HzGLNjoNelxXyFPAiEhTxMZE82+1i3r2rMbvS0ukyZCbvztzISXWnDBgFvIgE1WW1SjNxQBtaVy/J01+v5M735pFy4KjXZYUkBbyIBF3JhFjevrMx/+pel/mb9nDlqzOYujrV67JCjgJeRDxhZtzWtBJf92tNqUKx3P3+fP4zYZXGms9FCngR8VT1Ugl80bclPZpVZNj0DdyoK2BzjQJeRDwXF+07ATv01ktYl5LG1a/NYOLyHV6Xle8p4EUkz7i6XhnGP9iayiUL0uejBfxj3Ar1mc8BBbyI5CkVSxTg0z7N6dmyCu/P3sT1b8xm065DXpeVLyngRSTPiY2K5MkutRl+R2O27DnCNYNnMm7Jz16Xle8o4EUkz+pYuzQT+rfmwgsK8eCoRTzx+TKOHleTTXYp4EUkTytXNJ6Pezfj/nbVGDXvJ7oOmcW6VA1zkB0KeBHJ86IjI/hL51p80LOJb5iDwbMYs2Cr12XleQp4Eck32tZMZEL/1jSoUJRHPl3CwNGLOZSuG31nRQEvIvlK6cJxfNSrKQMur8HYxdvoMmQmq7Yf8LqsPEkBLyL5TmSEMeDymozs1ZS0oyfo/vosvlIvm99RwItIvtWiWknGP9iaumWL0G/UIl6ctEbDD2eigBeRfC2xUCwj723KzZdWYMjUdfT+MImDR497XVaeELCAN7M4M5tnZkvMbIWZ/TNQ2xKR8BYbFcl/rruYp7vWYeqanVz3uq5+hcAewacDlznn6gMNgM5m1iyA2xORMGZm3NG8Mh/2bMLOtHS6Dp3FzOTwvsl3wALe+aT5v432P9Q4JiIB1aJ6Scb1bcUFheO44925vDNzI86FZ/QEtA3ezCLNbDGQCkx2zs0N5PZERMA3YNlnD7Tg8otK88zXK3l0zNKwHJUyoAHvnMtwzjUAygNNzKzu6cuYWW8zSzKzpJ07dwayHBEJIwmxUbzZoxEPdqjBmAVbufmtOaSG2b1fg9KLxjm3D5gKdD7DvLecc42dc40TExODUY6IhImICGNgx5q8cdslrN5+kGuHzGLJln1elxU0gexFk2hmRf3P44GOwOpAbU9EJCtXXlyGz+5vQWSEceOwH/li0TavSwqKQB7BlwGmmtlSYD6+NvivA7g9EZEs1S5bmHF/bkmDCkUZMHox/5mwiowQvygqKlAv7JxbCjQM1OuLiJyrEgmxfNSrKU9/tZJh0zewJuUgr97ckCLx0V6XFhC6klVEwkp0ZATPdKvLv7rXZWbyLrq/Pov1O9P+eMV8SAEvImHptqaVGNmrKfsOH6f70FnM2bDb65JynQJeRMJW06ol+LJvS0oVjuOOd+bx5eLQOvmqgBeRsFaheAE+69OChhWL0v/jxbzxw/qQufJVAS8iYa9IgWhG3NOELvXL8vzE1fz9y+WcyDjpdVk5FrBeNCIi+UlsVCSv3tSAckXjeXPaerbvO8rgWxtSICb/xqSO4EVE/CIijMevrMUz3eoydU0qN781h50H070u67wp4EVETnN7s0oMv6MxySlpdH99FutS82c3SgW8iMgZdLioNKPva8bR4xlc/8Zs5m3c43VJ50wBLyKShXrlizL2gZaUSIihx9tz892NvRXwIiJnUaF4AT6/vwX1K/hu7P3W9PzTjVIBLyLyB4oWiOHDe5pydb0y/HvCap4atyJfDFSWf/v/iIgEUVx0JINvbkj5ovEMm76Bn/cdZfAtDYmPifS6tCzpCF5EJJsiIownrrqIp7vWYcrqFG4ePoddaXm3G6UCXkTkHN3RvDLDbm/Mmh0HuO712Xl2NEoFvIjIeehYuzQf927OofQT3PDGbJZv2+91Sb+jgBcROU8NKhTls/tbUCAmiluGz2HB5r1el/QbCngRkRyoXLIgn/RpTomCMdz+zlxmr9/ldUm/UMCLiORQuaLxfHJfc8oXi+fu9+YzdXWq1yUBCngRkVxRqnAcH/duTo3SCfT+MIlvlm33uiQFvIhIbileMIb/3duMeuWL0vd/Cxm7aKun9SjgRURyUeG4aEb0bEKzqiUY+MkS/jf3J89qUcCLiOSygrFRvHvXpbSrmchfxy7j7RkbPKlDAS8iEgBx0ZEMu70xV9a9gGfHr2Lw98lBH6RMAS8iEiAxUREMvqUh1zUsx0uT1/LfSWuCGvIabExEJICiIiN48U/1iY+J5I0f1nPkWAZPXlObiAgL/LYDvgURkTAXEWE8260u8dGRvD1zI4ePneA/19UjMsAhr4AXEQkCM+P/rr6IArFRvPZ9MkeOn+TlG+sTHRm4lnIFvIhIkJgZAzvWJD46kucnrubIsQyG3NqQuOjAjCmvk6wiIkF2f7tq/PPaOny3KoV7RyRx5FhGQLajgBcR8cCdLSrz3xvqMWvdLu58dx6Hj53I9W2oiUZExCM3Nq5AfHQkM5N3EReV+800CngREQ91qV+WLvXLBuS11UQjIhKiFPAiIiFKAS8iEqIU8CIiIUoBLyISohTwIiIhSgEvIhKiFPAiIlscqosAAAbOSURBVCHKgn2HkbMxs53A5vNcvSSwKxfLyW2qL2dUX86ovpzJy/VVcs4lnmlGngr4nDCzJOdcY6/ryIrqyxnVlzOqL2fyen1ZURONiEiIUsCLiISoUAr4t7wu4A+ovpxRfTmj+nImr9d3RiHTBi8iIr8VSkfwIiKSiQJeRCRE5buAN7POZrbGzNaZ2eNnmB9rZqP98+eaWeUg1lbBzKaa2UozW2Fm/c+wTDsz229mi/2PJ4NVn3/7m8xsmX/bSWeYb2b2mn//LTWzS4JY24WZ9stiMztgZgNOWyao+8/M3jWzVDNbnmlacTObbGbJ/q/Fslj3Tv8yyWZ2ZxDre8HMVvt/f2PNrGgW6571vRDA+v5hZtsy/Q6vymLds37WA1jf6Ey1bTKzxVmsG/D9l2POuXzzACKB9UBVIAZYAtQ+bZkHgDf9z28GRgexvjLAJf7nhYC1Z6ivHfC1h/twE1DyLPOvAr4BDGgGzPXwd70D30Ucnu0/oA1wCbA807T/Ao/7nz8OPH+G9YoDG/xfi/mfFwtSfZ2AKP/z589UX3beCwGs7x/AI9n4/Z/1sx6o+k6b/xLwpFf7L6eP/HYE3wRY55zb4Jw7BnwMdD1tma7AB/7nY4AOZmbBKM45t905t9D//CCwCigXjG3noq7ACOczByhqZmU8qKMDsN45d75XNucK59x0YM9pkzO/xz4Aup1h1SuAyc65Pc65vcBkoHMw6nPOfeucO3UH5zlA+dzebnZlsf+yIzuf9Rw7W33+3LgRGJXb2w2W/Bbw5YAtmb7fyu8D9Jdl/G/y/UCJoFSXib9pqCEw9wyzm5vZEjP7xszqBLUwcMC3ZrbAzHqfYX529nEw3EzWHywv9x9Aaefcdv/zHUDpMyyTV/ZjT3z/kZ3JH70XAunP/iakd7No4soL+681kOKcS85ivpf7L1vyW8DnC2aWAHwGDHDOHTht9kJ8zQ71gcHAF0Eur5Vz7hLgSqCvmbUJ8vb/kJnFANcCn55httf77zec73/1PNnX2Mz+DzgBjMxiEa/eC28A1YAGwHZ8zSB50S2c/eg9z3+W8lvAbwMqZPq+vH/aGZcxsyigCLA7KNX5thmNL9xHOuc+P32+c+6Acy7N/3wCEG1mJYNVn3Num/9rKjAW37/CmWVnHwfalcBC51zK6TO83n9+KaearfxfU8+wjKf70czuAq4BbvP/EfqdbLwXAsI5l+Kcy3DOnQSGZ7Fdr/dfFHAdMDqrZbzaf+civwX8fKCGmVXxH+XdDIw7bZlxwKkeCzcAU7J6g+c2f5vdO8Aq59zLWSxzwalzAmbWBN/vICh/gMysoJkVOvUc38m45actNg64w9+bphmwP1NzRLBkeeTk5f7LJPN77E7gyzMsMwnoZGbF/E0QnfzTAs7MOgOPAdc65w5nsUx23guBqi/zOZ3uWWw3O5/1QLocWO2c23qmmV7uv3Pi9Vnec33g6+WxFt8Z9v/zT3sa35sZIA7fv/brgHlA1SDW1grfv+tLgcX+x1VAH6CPf5k/Ayvw9QqYA7QIYn1V/dtd4q/h1P7LXJ8BQ/37dxnQOMi/34L4ArtIpmme7T98f2i2A8fxtQPfg++czvdAMvAdUNy/bGPg7Uzr9vS/D9cBdwexvnX42q9PvQdP9SorC0w423shSPV96H9vLcUX2mVOr8///e8+68Gozz/9/VPvuUzLBn3/5fShoQpEREJUfmuiERGRbFLAi4iEKAW8iEiIUsCLiIQoBbyISIhSwIvkAv8ol197XYdIZgp4EZEQpYCXsGJmPcxsnn8M72FmFmlmaWY2yHxj+H9vZon+ZRuY2ZxM46oX80+vbmbf+Qc8W2hm1fwvn2BmY/xjsY8M1iimIllRwEvYMLOLgJuAls65BkAGcBu+q2eTnHN1gGnAU/5VRgB/cc7Vw3fl5anpI4GhzjfgWQt8V0KCb/TQAUBtfFc6tgz4DyVyFlFeFyASRB2ARsB8/8F1PL6Bwk7y66BSHwGfm1kRoKhzbpp/+gfAp/7xR8o558YCOOeOAvhfb57zj13ivwtQZWBm4H8skTNTwEs4MeAD59wTv5lo9vfTljvf8TvSMz3PQJ8v8ZiaaCScfA/cYGal4Jd7q1bC9zm4wb/MrcBM59x+YK+ZtfZPvx2Y5nx36tpqZt38rxFrZgWC+lOIZJOOMCRsOOdWmtnf8N2FJwLfCIJ9gUNAE/+8VHzt9OAbCvhNf4BvAO72T78dGGZmT/tf409B/DFEsk2jSUrYM7M051yC13WI5DY10YiIhCgdwYuIhCgdwYuIhCgFvIhIiFLAi4iEKAW8iEiIUsCLiISo/wfuLFsKPwhNHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "6988df8d-61eb-4287-cc8f-226efb50e1a1"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "我。如果另一個上了，或是他掏出了刀子，我\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "的」果另一個人一，我是我的出了一子，我就\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]\n",
        "\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd640f6-c1c2-479b-a71b-d6d18896d849"
      },
      "source": [
        "init_seq = \"我們\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "我們的淒然，我們的愕然，不是一個通言。他只以說，這是我的誇情，我在我的誤子基會的時刻，我房上了門房的聲音，我都看到了那一堆的岩石，我不知道這一點的可笑。他只是梧恕的理由，我只是說，這是我的最情，我竟不能出到我的忽要是這樣的生活。」我說：「您知道，我們的心音很多。我說：「您知道，我們的朋友。」我說：「是什麼？」我回答說我的意思。我問我是不是認為我的案子。」我說：「您知道，我們的朋友。」我說：「我們的朋友。」我回答說我對此了個什麼，他說我糊婚的是，他還是養老院的人。他說：「您知道，我們的律師對我的律師討論控告一個辦事處，我的心音是不發抖的。我的律師對我說：「您知道，我們的律師對我的律師討論控告一個辦事處，我的心音是不發抖的。我的律師對我說：「您知道，我們的律師對我的僻兒漢。他們問我是否是這樣的話，我就不說話了。我想知道我是否塵且的關係。我想知道我是否揍了。他想知道我是否有一個生活。」我問我是不是認為我的案子。他鮮磨的時候，我想知道我是否是穿得酸。我跟他說他不喜歡警察。我說：「您知道，我們的朋友。」檢察官問他是否是不是我的朋友。」檢察官問他是否允是我的里魂。我遍得很快。」他的聲音伙，我感到有點兒"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "dd8b2f41-68ba-4bdd-db04-a2ba45b75a5a"
      },
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-eb8bb33176bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "source": [
        "result = generateWords(input,500)\n",
        "print(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}